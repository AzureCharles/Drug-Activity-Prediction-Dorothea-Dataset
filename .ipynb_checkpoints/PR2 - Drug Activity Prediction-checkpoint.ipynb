{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, recall_score\n",
    "#Read the input files and read every line\n",
    "def loadData(trainingFile, testingFile):\n",
    "    \n",
    "    def convertDataframe(inputFile):\n",
    "        data = pd.DataFrame(columns=range(100000))\n",
    "        \n",
    "        for i in range(len(inputFile)):\n",
    "            record = np.fromstring(inputFile[i], dtype=int, sep=' ')\n",
    "            record_bool = [0 for j in range(100000)]\n",
    "            for col in record:\n",
    "                record_bool[col-1] = 1\n",
    "            \n",
    "            data.loc[i] = record_bool\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    with open(trainingFile, \"r\") as fr1:\n",
    "        trainFile = fr1.readlines()\n",
    "    \n",
    "    #Split each line in the two files into label and data  \n",
    "    train_data_list = []\n",
    "    train_labels_list = []\n",
    "    \n",
    "    for inputData in trainFile:\n",
    "        train_labels_list.append(inputData[0])\n",
    "        #Remove the activity label (0/1) and new line character from each record\n",
    "        inputData = inputData.replace(\"0\\t\", \"\")\n",
    "        inputData = inputData.replace(\"1\\t\", \"\")\n",
    "        inputData = inputData.replace(\"\\n\", \"\")\n",
    "        train_data_list.append(inputData)\n",
    "    \n",
    "    train_labels = np.asarray(train_labels_list)\n",
    "    train_data = convertDataframe(train_data_list)\n",
    "        \n",
    "    with open(testingFile, \"r\") as fr2:\n",
    "        testFile = fr2.readlines()\n",
    "    \n",
    "    test_data = convertDataframe(testFile)\n",
    "            \n",
    "    return train_data, test_data, train_labels\n",
    "\n",
    "# Project data on a reduced dimensionality k using PCA\n",
    "def pca(train_data, test_data, k=500):\n",
    "\n",
    "    pca = sklearnPCA(n_components = k)\n",
    "    PCA_projected_trainData = pca.fit_transform(train_data)\n",
    "    PCA_projected_testData = pca.transform(test_data)\n",
    "    \n",
    "    return PCA_projected_trainData, PCA_projected_testData\n",
    "\n",
    "# Save data handled by PCA\n",
    "def pcaData2csv(csvpath1,csvpath2, train_data,test_data):\n",
    "    dftrain=pd.DataFrame(train_data)\n",
    "    dftest=pd.DataFrame(test_data)\n",
    "    dftrain.to_csv(csvpath1,index=False,sep=',')\n",
    "    dftest.to_csv(csvpath2,index=False,sep=',')\n",
    "    if os.path.exists(csvpath1):\n",
    "        print(\"PCA projected train data has been written into csv files in:\"+str(csvpath1))\n",
    "        if os.path.exists(csvpath2):\n",
    "            print(\"PCA projected test data has been written into csv files in:\"+str(csvpath2))\n",
    "        else:\n",
    "            raise Warning(\"File written failed in:\"+str(csvpath2))\n",
    "    else:raise Warning(\"File written failed in:\"+str(csvpath1))\n",
    "    # 抛出dataframe类型以备其他用途\n",
    "    return dftrain,dftest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "主成分分析（Principal Components Analysis），简称PCA，是一种数据降维技术，用于数据预处理。\n",
    "\n",
    "PCA的一般步骤是：先对原始数据零均值化，然后求协方差矩阵，接着对协方差矩阵求特征向量和特征值，这些特征向量组成了新的特征空间。\n",
    "\n",
    "sklearn.decomposition.PCA(n_components=None, copy=True, whiten=False)\n",
    "\n",
    "## 参数：\n",
    "\n",
    "n_components:  \n",
    "\n",
    "意义：PCA算法中所要保留的主成分个数n，也即保留下来的特征个数n\n",
    "\n",
    "类型：int 或者 string，缺省时默认为None，所有成分被保留。\n",
    "\n",
    "          赋值为int，比如n_components=1，将把原始数据降到一个维度。\n",
    "\n",
    "          赋值为string，比如n_components='mle'，将自动选取特征个数n，使得满足所要求的方差百分比。\n",
    "\n",
    "copy:\n",
    "\n",
    "类型：bool，True或者False，缺省时默认为True。\n",
    "意义：表示是否在运行算法时，将原始训练数据复制一份。若为True，则运行PCA算法后，原始训练数据的值不            会有任何改变，因为是在原始数据的副本上进行运算；若为False，则运行PCA算法后，原始训练数据的              值会改，因为是在原始数据上进行降维计算。\n",
    "\n",
    "whiten:\n",
    "\n",
    "类型：bool，缺省时默认为False\n",
    "\n",
    "意义：白化，使得每个特征具有相同的方差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Read the training and the test data set and get 3 separate dataframes of training reviews, test reviews and training labels\n",
    "train_data, test_data, train_labels = loadData('train.dat', 'test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PCA_Data/PCAProjectedTrainData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20128\\1644731672.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcsv_path1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"PCA_Data/PCAProjectedTrainData.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcsv_path2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"PCA_Data/PCAProjectedTestData.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpcaData2csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcsv_path2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPCA_projected_testData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPCA_projected_testData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20128\\4181604694.py\u001b[0m in \u001b[0;36mpcaData2csv\u001b[1;34m(csvpath1, csvpath2, train_data, test_data)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mdftrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mdftest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mdftrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvpath1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mdftest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvpath1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvpath1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3480\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3481\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3482\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3483\u001b[0m         )\n\u001b[0;32m   3484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         ) as handles:\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PCA_Data/PCAProjectedTrainData.csv'"
     ]
    }
   ],
   "source": [
    "#Reduce the number of dimensions from 100000 to 500 using PCA\n",
    "PCA_projected_trainData, PCA_projected_testData = pca(train_data, test_data, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA projected train data has been written into csv files in:PCAProjectedTrainData.csv\n",
      "PCA projected test data has been written into csv files in:PCAProjectedTestData.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(          0         1         2         3         4         5         6    \\\n",
       " 0   -1.125870 -0.128440 -0.102968 -0.313309  0.160699  0.130207  0.063688   \n",
       " 1   -1.308434  0.193499 -0.405027 -0.140166 -0.031614  0.171217 -0.039018   \n",
       " 2   -1.405040  0.097894 -0.345446 -0.159103  0.093697  0.389293  0.125315   \n",
       " 3   -1.361406  0.191011 -0.230124 -0.239734 -0.099480  0.562027 -0.132629   \n",
       " 4   -1.092500  0.367378 -0.308837 -0.146437  0.008938  0.363181  0.104377   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 795 -1.338701  0.192725 -0.293317 -0.212179  0.117836  0.274895  0.060185   \n",
       " 796 -1.295856  0.028062 -0.169337 -0.241278 -0.034376  0.235111 -0.211375   \n",
       " 797  4.850017 -4.857741  3.792205 -0.415892  0.329830  1.028058 -1.061934   \n",
       " 798 -1.226655  0.281766 -0.441692 -0.202438  0.130427  0.233482  0.080333   \n",
       " 799 -1.411278  0.394711 -0.202601 -0.235139 -0.020704  0.281221  0.390748   \n",
       " \n",
       "           7         8         9    ...       490       491       492  \\\n",
       " 0    0.450884 -0.154832  0.094656  ... -0.942231 -0.710508 -1.593550   \n",
       " 1    0.033235 -0.045560 -0.115547  ... -0.277772  0.298985 -0.582787   \n",
       " 2    0.167004 -0.139987  0.054377  ...  1.086223 -0.344951 -0.524864   \n",
       " 3   -0.003174  0.074802 -0.262060  ...  0.375274  1.486699  1.453198   \n",
       " 4    0.031781 -0.103785 -0.185732  ... -0.329643 -0.881579 -2.053264   \n",
       " ..        ...       ...       ...  ...       ...       ...       ...   \n",
       " 795  0.419261  0.037493 -0.247369  ...  1.321768  0.731607 -1.006883   \n",
       " 796  0.203449 -0.455945  0.534514  ...  1.408814 -0.797469 -0.192925   \n",
       " 797 -0.623767 -0.294806  0.648689  ... -0.098947 -0.456302  0.047396   \n",
       " 798  0.256986 -0.108790 -0.036398  ...  0.859545  0.405930  1.638970   \n",
       " 799 -0.087518  0.245637 -0.073908  ...  1.298021  0.991297  0.726671   \n",
       " \n",
       "           493       494       495       496       497       498       499  \n",
       " 0   -1.547668  0.520391 -0.077098 -1.002925 -1.496591  1.259699  1.231847  \n",
       " 1    0.365523  0.673148 -0.926880  0.028926 -1.172122 -0.097717 -0.016697  \n",
       " 2    0.205599  1.144148  1.481138  1.585460 -1.036646 -0.847469 -1.418588  \n",
       " 3    1.989927 -0.828713 -0.427430  0.880818  1.302992 -1.709250 -1.651523  \n",
       " 4    0.436233 -0.174708  0.834436 -0.032305  0.608882  0.298259 -0.287874  \n",
       " ..        ...       ...       ...       ...       ...       ...       ...  \n",
       " 795  0.826822 -1.484405 -0.833131 -0.648284  0.986573 -0.714672 -0.244197  \n",
       " 796  2.028159 -0.118703 -1.564566 -0.459609 -0.024006 -1.141558  1.285482  \n",
       " 797 -0.320866  0.073394  0.758111  0.454436 -0.086788 -0.471719 -0.209311  \n",
       " 798 -1.202973  0.120751  0.740240  1.225846 -0.994847 -0.906799 -1.729944  \n",
       " 799 -0.791503 -1.195514 -0.372271 -0.018020 -0.070395  1.440330  0.291839  \n",
       " \n",
       " [800 rows x 500 columns],\n",
       "           0         1         2         3         4         5         6    \\\n",
       " 0   -0.585532 -0.242955 -0.099595  0.038893 -0.088557 -0.092659  0.110739   \n",
       " 1   -1.153384  0.058956 -0.123445 -0.040082  0.006687  0.145195  0.093742   \n",
       " 2   -0.743940  0.785031  0.609502  0.110150 -0.000700  0.002944  1.509173   \n",
       " 3   -1.020475  0.044453 -0.109058 -0.119675  0.203404  0.181679 -0.117494   \n",
       " 4   -0.738692 -0.228193  0.011234 -0.178686  0.125707  0.244340 -0.139474   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 345 -1.125822  0.055321 -0.253510 -0.136564  0.119390  0.362200  0.027077   \n",
       " 346 -1.176943  0.207877 -0.249692 -0.104512 -0.013163  0.321181 -0.029588   \n",
       " 347 -0.974204  0.209110 -0.457698 -0.197639 -0.034444 -0.109716 -0.224377   \n",
       " 348 -1.121439  0.739081  0.269606  0.182804 -0.045575  0.223005  0.164265   \n",
       " 349 -1.278631  0.067150 -0.271891 -0.131768  0.054142  0.246059 -0.051287   \n",
       " \n",
       "           7         8         9    ...       490       491       492  \\\n",
       " 0    1.034827 -0.116528  0.456804  ... -0.005238 -0.043262 -0.083025   \n",
       " 1    0.154158 -0.047715 -0.087772  ... -0.220778  0.174561  0.098668   \n",
       " 2   -0.711247  0.050048  0.055883  ... -0.073253 -0.001829 -0.116515   \n",
       " 3   -0.031630 -0.216324 -0.022526  ...  0.126951 -0.119255 -0.070467   \n",
       " 4    0.035177 -0.296949  0.101414  ... -0.063338  0.062989 -0.059836   \n",
       " ..        ...       ...       ...  ...       ...       ...       ...   \n",
       " 345  0.194034  0.068986  0.016937  ...  0.025562 -0.064589 -0.039051   \n",
       " 346  0.114896  0.044093 -0.161104  ... -0.197236  0.055305  0.078090   \n",
       " 347  0.098632 -0.111074  0.067850  ... -0.040796  0.076502 -0.029652   \n",
       " 348 -0.061091 -0.044876 -0.015292  ... -0.125756 -0.244128  0.007772   \n",
       " 349  0.193161 -0.278499  0.099418  ... -0.033586 -0.025834 -0.053413   \n",
       " \n",
       "           493       494       495       496       497       498       499  \n",
       " 0   -0.280319  0.114564 -0.167244 -0.142699 -0.191589  0.104857 -0.163431  \n",
       " 1    0.148170  0.012634  0.089338 -0.172281  0.056362 -0.064514 -0.002741  \n",
       " 2    0.030351 -0.148225  0.054517 -0.029047 -0.147415  0.202197  0.261052  \n",
       " 3   -0.061540 -0.176689 -0.120309 -0.145730  0.002009  0.156367  0.116916  \n",
       " 4    0.134386 -0.265960  0.085940 -0.067744  0.056425  0.198260  0.089265  \n",
       " ..        ...       ...       ...       ...       ...       ...       ...  \n",
       " 345  0.059754 -0.007212  0.201667  0.011507 -0.243359 -0.106938  0.045320  \n",
       " 346 -0.222238 -0.256951  0.205917  0.026577  0.138708 -0.172830  0.034509  \n",
       " 347 -0.049726  0.240339 -0.131025  0.261714  0.265901 -0.103693  0.032198  \n",
       " 348 -0.003551  0.014357 -0.264498 -0.085942 -0.037535 -0.015441 -0.123248  \n",
       " 349  0.154498  0.139552  0.333819  0.076111 -0.179451  0.025270 -0.001804  \n",
       " \n",
       " [350 rows x 500 columns])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path1=r\"PCAProjectedTrainData.csv\"\n",
    "csv_path2=r\"PCAProjectedTestData.csv\"\n",
    "pcaData2csv(csv_path1,csv_path2, PCA_projected_trainData,PCA_projected_testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 伯努利朴素贝叶斯BernoulliNB\n",
    "\n",
    "多项式朴素贝叶斯可同时处理二项分布（抛硬币）和多项分布（掷骰子），其中二项分布又叫做伯努利分布，它是一种现实中常见，并且拥有很多优越数学性质的分布。因此，既然有着多项式朴素贝叶斯，我们自然也就又专门用来处理二项分布的朴素贝叶斯：伯努利朴素贝叶斯。\n",
    "\n",
    "伯努利贝叶斯类BernoulliN假设数据服从多元伯努利分布，并在此基础上应用朴素贝叶斯的训练和分类过程。多元伯努利分布简单来说，就是数据集中可以存在多个特征，但每个特征都是二分类的，可以以布尔变量表示，也可以表示为{0，1}或者{-1，1}等任意二分类组合。因此，这个类要求将样本转换为二分类特征向量，如果数据本身不是二分类的，那可以使用类中专门用来二值化的参数binarize来改变数据。\n",
    "\n",
    "伯努利朴素贝叶斯与多项式朴素贝叶斯非常相似，都常用于处理文本分类数据。但由于伯努利朴素贝叶斯是处理二项分布，所以它更加在意的是“存在与否”，而不是“出现多少次”这样的次数或频率，这是伯努利贝叶斯与多项式贝叶斯的根本性不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, average_precision_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def resultAnalysis(testData,testLabels,pred,proba,_module=None):\n",
    "    xmodulelist = ['macro','micro','weighted','non-avg']\n",
    "    criteion = ['Accuracy','Precision','Recall','F1_score','AUC','AUPRC']\n",
    "    df = pd.DataFrame(index=xmodulelist,columns=criteion)\n",
    "    \n",
    "    \n",
    "    if _module not in xmodulelist:\n",
    "        \n",
    "        df['Accuracy']['non-avg']=round(accuracy_score(testLabels,pred),3)\n",
    "        df['Precision']['non-avg']=round(precision_score(testLabels,pred,),3)\n",
    "        df['Recall']['non-avg']=round(recall_score(testLabels,pred,),3)\n",
    "        df['AUC']['non-avg']=round(roc_auc_score(testLabels,proba,),3)\n",
    "        df['AUPRC']['non-avg']=round(average_precision_score(testLabels,pred,),3)\n",
    "        df['F1_score']['non-avg']=round(f1_score(testLabels,pred,),3)\n",
    "        print(df.iloc[3,:])\n",
    "            \n",
    "    else:\n",
    "        df['Accuracy'][_module]=round(accuracy_score(testLabels,pred),3)\n",
    "        df['Precision'][_module]=round(precision_score(testLabels,pred,average=_module),3)\n",
    "        df['Recall'][_module]=round(recall_score(testLabels,pred,average=_module),3)\n",
    "        df['AUC'][_module]=round(roc_auc_score(testLabels,proba,average=_module),3)\n",
    "        df['AUPRC'][_module]=round(average_precision_score(testLabels,pred,average=_module),3)\n",
    "        df['F1_score'][_module]=round(f1_score(testLabels,pred,average=_module),3)\n",
    "        print(df.loc[_module,:])\n",
    "    print(confusion_matrix(testLabels,pred))\n",
    "    return classification_report(testLabels,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(trainingFile, \"r\") as fr1:\n",
    "#    trainFile = fr1.readlines()\n",
    "def getListFromFile(_filename):\n",
    "    _list = []\n",
    "    with open(_filename, \"r\") as fr3:\n",
    "        dat_r = fr3.readlines()\n",
    "    for inputData in dat_r:\n",
    "        _list.append(inputData[0])\n",
    "    target = np.asarray(_list)\n",
    "    return target\n",
    "\n",
    "test_labels = getListFromFile('valid_labels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the result to a .dat file\n",
    "def getPredictionFile(filename,preds):\n",
    "    with open(filename,\"w\",encoding=\"utf-8\") as output:\n",
    "        \n",
    "        #output = open('output-k-100-PCA-BNBC.dat', 'w')\n",
    "        output.writelines( \"%s\\n\" % pred for pred in preds )\n",
    "        #output.close()\n",
    "        print(\"%s written completed.\" % filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy      0.94\n",
      "Precision    0.741\n",
      "Recall       0.588\n",
      "F1_score     0.656\n",
      "AUC           0.88\n",
      "AUPRC        0.476\n",
      "Name: non-avg, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       316\n",
      "           1       0.74      0.59      0.66        34\n",
      "\n",
      "    accuracy                           0.94       350\n",
      "   macro avg       0.85      0.78      0.81       350\n",
      "weighted avg       0.94      0.94      0.94       350\n",
      "\n",
      "\tAccuracy:0.940\n",
      "\tPrecision:0.741\n",
      "\tRecall:0.588\n",
      "\tF1_score:0.656\n",
      "\tAUC:0.880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BernoulliNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def BNBC2(trainData,trainLabels, testData,testLabels):\n",
    "    trainLabels=trainLabels.astype(int)\n",
    "    testLabels=testLabels.astype(int)#二值化\n",
    "    \n",
    "    clf = BernoulliNB (alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)\n",
    "    clf.fit(trainData,trainLabels)\n",
    "    \n",
    "    pred = clf.predict(testData)\n",
    "    proba = clf.predict_proba(testData)[:,1]\n",
    "    score = clf.score(testData,testLabels)\n",
    "    fpr, tpr, thresholds = roc_curve(testLabels, proba)\n",
    "    rocauc=auc(fpr, tpr)\n",
    "    print(resultAnalysis(testData,testLabels,pred,proba,))\n",
    "    #print(proba)\n",
    "    print(\"\\tAccuracy:{:.3f}\".format(score))\n",
    "    print(\"\\tPrecision:{:.3f}\".format(precision_score(testLabels,pred)))\n",
    "    print(\"\\tRecall:{:.3f}\".format(recall_score(testLabels,pred)))\n",
    "    print(\"\\tF1_score:{:.3f}\".format(f1_score(testLabels,pred)))\n",
    "    print(\"\\tAUC:{:.3f}\".format(roc_auc_score(testLabels,proba)))\n",
    "    return pred\n",
    "\n",
    "BNBC2(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     0.846\n",
      "Precision    0.348\n",
      "Recall       0.676\n",
      "F1_score      0.46\n",
      "AUC          0.838\n",
      "AUPRC        0.267\n",
      "Name: non-avg, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       316\n",
      "           1       0.35      0.68      0.46        34\n",
      "\n",
      "    accuracy                           0.85       350\n",
      "   macro avg       0.65      0.77      0.69       350\n",
      "weighted avg       0.90      0.85      0.87       350\n",
      "\n",
      "\tAccuracy:0.846\n",
      "\tPrecision:0.348\n",
      "\tRecall:0.676\n",
      "\tAUC:0.838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "def min_max_normalization(np_array):\n",
    "    min_max_scaler = MinMaxScaler(feature_range=[1,7])\n",
    "    ret = min_max_scaler.fit_transform(np_array)\n",
    "    return ret\n",
    "\n",
    "def CNB(trainData,trainLabels, testData,testLabels):\n",
    "\n",
    "    trainLabels=trainLabels.astype(int)\n",
    "    testLabels=testLabels.astype(int)#二值化\n",
    "    \n",
    "    trainData=min_max_normalization(trainData)\n",
    "    testData=min_max_normalization(testData)\n",
    "    \n",
    "    clf = ComplementNB(alpha=1.0, fit_prior=True, class_prior=None, norm=False)\n",
    "    clf.fit(trainData,trainLabels)\n",
    "\n",
    "    pred = clf.predict(testData)\n",
    "    proba = clf.predict_proba(testData)[:,1]\n",
    "    score = clf.score(testData,testLabels)\n",
    "    fpr, tpr, thresholds = roc_curve(testLabels, proba)\n",
    "    #rocauc=auc(fpr, tpr)\n",
    "    print(resultAnalysis(testData,testLabels,pred,proba,_module='A'))\n",
    "    # 以下针对少数类\n",
    "    print(\"\\tAccuracy:{:.3f}\".format(score))\n",
    "    print(\"\\tPrecision:{:.3f}\".format(precision_score(testLabels,pred)))\n",
    "    print(\"\\tRecall:{:.3f}\".format(recall_score(testLabels,pred)))\n",
    "    print(\"\\tAUC:{:.3f}\".format(roc_auc_score(testLabels,proba)))\n",
    "    return pred\n",
    "\n",
    "CNB(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCalculate Module:macro\n",
      "\tAccuracy:0.940\n",
      "\tPrecision:0.849\n",
      "\tRecall:0.783\n",
      "\tF1_score:0.811\n",
      "\tAUC:0.880\n",
      "\tCalculate Module:micro\n",
      "\tAccuracy:0.940\n",
      "\tPrecision:0.940\n",
      "\tRecall:0.940\n",
      "\tF1_score:0.940\n",
      "\tAUC:0.880\n",
      "\tCalculate Module:weighted\n",
      "\tAccuracy:0.940\n",
      "\tPrecision:0.936\n",
      "\tRecall:0.940\n",
      "\tF1_score:0.937\n",
      "\tAUC:0.880\n",
      "\tAccuracy:0.857\n",
      "\tPrecision:0.741\n",
      "\tRecall:0.588\n",
      "\tAUC:0.880\n",
      "output-k-100-PCA-BNBC.dat written completed.\n"
     ]
    }
   ],
   "source": [
    "#Classify data using Naive Bayes Classifier\n",
    "\n",
    "getPredictionFile('output-k-100-PCA-BNBC.dat',BNBC2(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    #num = min(len(_preds),len(_labels))\n",
    "    #print(num)\n",
    "    labels=labels.astype(int)\n",
    "    preds=preds.astype(int)\n",
    "    num=len(preds)\n",
    "    #print(preds)\n",
    "    correct = 0\n",
    "    print(preds[:10])\n",
    "    print(labels[:10])\n",
    "    tp = 0 #true_positives\n",
    "    tn = 0 #true_negatives\n",
    "    fp = 0 #false_positives\n",
    "    fn = 0 #false_negatives\n",
    "    for i in range(num):\n",
    "        if preds[i]==labels[i]:\n",
    "            correct+=1\n",
    "            if preds[i]:\n",
    "                tp+=1\n",
    "            else:tn+=1\n",
    "        else:\n",
    "            if preds[i]:\n",
    "                fp+=1\n",
    "            else:fn+=1\n",
    "    print(\"预测总数:%s\" % len(preds))\n",
    "    print(\"标签数:%s\" % len(labels))\n",
    "    print(\"正确数:%s\" % correct)\n",
    "    print(\"TP:FP\",(tp,fp))\n",
    "    print(\"TN:FN\",(tn,fn))\n",
    "    print(\"Recall\",recall_score(labels.astype(int),preds.astype(int),pos_label=1))\n",
    "    _acc = correct/len(labels)\n",
    "    _prec = tp/(tp+fp)\n",
    "    _recall = tp/(tp+fn)\n",
    "    _fpr = fp/(fp+tn)\n",
    "    _tnr = tn/(fp+tn)\n",
    "    _f1 = 2*_prec*_recall/(_prec+_recall)\n",
    "    return({'ACC':_acc,'Precision':_prec,'Recall':_recall,'FPR':_fpr,'TNR':_tnr,'F1':_f1})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy：准确率\n",
    "\n",
    "也就是所有预测正确的和所有test集的比例。\n",
    "\n",
    "准确率=预测正确的样本数/所有样本数，即预测正确的样本比例（包括预测正确的正样本和预测正确的负样本）。\n",
    "\n",
    ">Accuracy = T/(T+F)\n",
    "\n",
    "### Precision：查准率\n",
    "\n",
    ">Precision=TP/(TP+FP)\n",
    "\n",
    "用于衡量模型对某一类的预测有多准。\n",
    "\n",
    "### Recall：召回率（真正类率）\n",
    "\n",
    ">Recall = TP/(TP+FN)\n",
    "\n",
    "指的是某个类别的Recall。Recall表示某一类样本，预测正确的与所有Ground Truth的比例。\n",
    "\n",
    "### FPR\n",
    "\n",
    ">FPR = FP/(TN+FP)\n",
    "\n",
    "代表分类器预测的正类中实际负实例占所有负实例的比例。\n",
    ">FPR = 1 - TNR\n",
    "\n",
    "### TNR\n",
    "\n",
    ">TNR = TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn import svm\n",
    "#from sklearn.metrics import roc_curve, roc_auc_score, recall_score, precision_score\n",
    "#from imblearn import specificity_score\n",
    "\n",
    "def SVMC2(trainData,trainLabels, testData,testLabels, _kernel=\"linear\",weights='balanced'):\n",
    "    #clf = svm.SVC(gamma='scale', class_weight=weights)\n",
    "    #clf.fit(trainData,trainLabels)\n",
    "    trainLabels=trainLabels.astype(int)\n",
    "    testLabels=testLabels.astype(int)#二值化\n",
    "    \n",
    "    clf_proba = svm.SVC(kernel=_kernel,C=1.0,probability=True).fit(trainData,trainLabels)\n",
    "    #print(clf_proba.decision_function(testData).shape)\n",
    "    #predictions = clf.predict(testData)\n",
    "    \n",
    "    clf_pred = clf_proba.predict(testData)\n",
    "    \n",
    "    result = clf_proba.score(testData, testLabels)\n",
    "    score = clf_proba.decision_function(testData)\n",
    "    \n",
    "    rocauc = roc_auc_score(testLabels, score)\n",
    "    recall = recall_score(testLabels, clf_pred)\n",
    "    precision = precision_score(testLabels, clf_pred)\n",
    "    \n",
    "    print(resultAnalysis(testData,testLabels,clf_pred,score,_module='A'))\n",
    "    #print(\"\\tAccuracy:{:.3f}\".format(result))\n",
    "    #print(\"\\tPrecision:{:.3f}\".format(precision))\n",
    "    #print(\"\\tRecall:{:.3f}\".format(recall))\n",
    "    #print(\"\\tSpecificity:{:.3f}\".format(specificity_score(testLabels, clf_pred)))\n",
    "    #print(\"\\tAUC:{:.3f}\".format(rocauc))\n",
    "    return clf_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 1 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0]\n",
      "预测总数:350\n",
      "标签数:350\n",
      "正确数:329\n",
      "TP:FP (20, 7)\n",
      "TN:FN (309, 14)\n",
      "Recall 0.5882352941176471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACC': 0.94,\n",
       " 'Precision': 0.7407407407407407,\n",
       " 'Recall': 0.5882352941176471,\n",
       " 'FPR': 0.022151898734177215,\n",
       " 'TNR': 0.9778481012658228,\n",
       " 'F1': 0.6557377049180328}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#朴素贝叶斯分类器\n",
    "bnbc_preds = getListFromFile('output-k-100-PCA-BNBC.dat')\n",
    "accuracy(bnbc_preds,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0]\n",
      "预测总数:350\n",
      "标签数:350\n",
      "正确数:325\n",
      "TP:FP (10, 1)\n",
      "TN:FN (315, 24)\n",
      "Recall 0.29411764705882354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACC': 0.9285714285714286,\n",
       " 'Precision': 0.9090909090909091,\n",
       " 'Recall': 0.29411764705882354,\n",
       " 'FPR': 0.0031645569620253164,\n",
       " 'TNR': 0.9968354430379747,\n",
       " 'F1': 0.4444444444444445}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "svm_preds = getListFromFile('output-k-100-PCA-SVM.dat')\n",
    "accuracy(svm_preds,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 1 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0]\n",
      "预测总数:350\n",
      "标签数:350\n",
      "正确数:329\n",
      "TP:FP (18, 5)\n",
      "TN:FN (311, 16)\n",
      "Recall 0.5294117647058824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACC': 0.94,\n",
       " 'Precision': 0.782608695652174,\n",
       " 'Recall': 0.5294117647058824,\n",
       " 'FPR': 0.015822784810126583,\n",
       " 'TNR': 0.9841772151898734,\n",
       " 'F1': 0.631578947368421}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "#test_labels = getListFromFile('valid_labels.dat')\n",
    "rfc_preds = getListFromFile('output-k-100-PCA-RFC.dat')\n",
    "accuracy(rfc_preds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCalculate Module:macro\n",
      "\tAccuracy:0.934\n",
      "\tPrecision:0.902\n",
      "\tRecall:0.688\n",
      "\tF1_score:0.748\n",
      "\tAUC:0.919\n",
      "\tCalculate Module:micro\n",
      "\tAccuracy:0.934\n",
      "\tPrecision:0.934\n",
      "\tRecall:0.934\n",
      "\tF1_score:0.934\n",
      "\tAUC:0.919\n",
      "\tCalculate Module:weighted\n",
      "\tAccuracy:0.934\n",
      "\tPrecision:0.930\n",
      "\tRecall:0.934\n",
      "\tF1_score:0.923\n",
      "\tAUC:0.919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       316\n",
      "           1       0.87      0.38      0.53        34\n",
      "\n",
      "    accuracy                           0.93       350\n",
      "   macro avg       0.90      0.69      0.75       350\n",
      "weighted avg       0.93      0.93      0.92       350\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SVMC(trainData,trainLabels, testData,testLabels,weights='balanced'):\n",
    "    \n",
    "    trainLabels=trainLabels.astype(int)\n",
    "    testLabels=testLabels.astype(int)#二值化\n",
    "    \n",
    "    clf_proba = svm.SVC(gamma='scale', class_weight=weights).fit(trainData,trainLabels)\n",
    "    #print(clf_proba.decision_function(testData).shape)\n",
    "    #predictions = clf.predict(testData)\n",
    "    \n",
    "    clf_pred = clf_proba.predict(testData)\n",
    "    \n",
    "    result = clf_proba.score(testData, testLabels)\n",
    "    score = clf_proba.decision_function(testData)\n",
    "    \n",
    "    rocauc = roc_auc_score(testLabels, score)\n",
    "    recall = recall_score(testLabels, clf_pred)\n",
    "    precision = precision_score(testLabels, clf_pred)\n",
    "    \n",
    "    print(resultAnalysis(testData,testLabels,clf_pred,score,_module='A'))\n",
    "    #print(\"\\tAccuracy:{:.3f}\".format(result))\n",
    "    #print(\"\\tPrecision:{:.3f}\".format(precision))\n",
    "    #print(\"\\tRecall:{:.3f}\".format(recall))\n",
    "    #print(\"\\tSpecificity:{:.3f}\".format(specificity_score(testLabels, clf_pred)))\n",
    "    #print(\"\\tAUC:{:.3f}\".format(rocauc))\n",
    "    return clf_pred\n",
    "SVMC(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     0.929\n",
      "Precision    0.909\n",
      "Recall       0.294\n",
      "F1_score     0.444\n",
      "AUC          0.927\n",
      "AUPRC        0.336\n",
      "Name: non-avg, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       316\n",
      "           1       0.91      0.29      0.44        34\n",
      "\n",
      "    accuracy                           0.93       350\n",
      "   macro avg       0.92      0.65      0.70       350\n",
      "weighted avg       0.93      0.93      0.91       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_preds=SVMC2(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-k-100-PCA-SVM.dat written completed.\n"
     ]
    }
   ],
   "source": [
    "#svm_preds = SVMC(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels)\n",
    "getPredictionFile('output-k-100-PCA-SVM.dat',svm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     0.929\n",
      "Precision    0.909\n",
      "Recall       0.294\n",
      "F1_score     0.444\n",
      "AUC          0.927\n",
      "AUPRC        0.336\n",
      "Name: non-avg, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       316\n",
      "           1       0.91      0.29      0.44        34\n",
      "\n",
      "    accuracy                           0.93       350\n",
      "   macro avg       0.92      0.65      0.70       350\n",
      "weighted avg       0.93      0.93      0.91       350\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0]\n",
      "预测总数:350\n",
      "标签数:350\n",
      "正确数:325\n",
      "TP:FP (10, 1)\n",
      "TN:FN (315, 24)\n",
      "Recall 0.29411764705882354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACC': 0.9285714285714286,\n",
       " 'Precision': 0.9090909090909091,\n",
       " 'Recall': 0.29411764705882354,\n",
       " 'FPR': 0.0031645569620253164,\n",
       " 'TNR': 0.9968354430379747,\n",
       " 'F1': 0.4444444444444445}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.metrics import roc_curve,precision_recall_curve,roc_auc_score,average_precision_score,f1_score\n",
    "#test_labels = getListFromFile('valid_labels.dat')\n",
    "weights = {'1':34,'0':316}\n",
    "\n",
    "svm_preds2=SVMC2(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels,weights=weights)\n",
    "#svm_f1 = f1_score(list(map(int,test_labels)),svm_score)\n",
    "#print('F1:',svm_f1)\n",
    "\n",
    "#svm_preds = getListFromFile('output-k-100-PCA-SVM.dat')\n",
    "accuracy(svm_preds2,test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     0.946\n",
      "Precision      0.8\n",
      "Recall       0.588\n",
      "F1_score     0.678\n",
      "AUC          0.932\n",
      "AUPRC        0.511\n",
      "Name: non-avg, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       316\n",
      "           1       0.80      0.59      0.68        34\n",
      "\n",
      "    accuracy                           0.95       350\n",
      "   macro avg       0.88      0.79      0.82       350\n",
      "weighted avg       0.94      0.95      0.94       350\n",
      "\n",
      "\tAccuracy:0.946\n",
      "\tPrecision:0.800\n",
      "\tRecall:0.588\n",
      "\tAUC:0.932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier     #随机森林\n",
    "\n",
    "def RFC(trainData,trainLabels, testData,testLabels):\n",
    "    \n",
    "    trainLabels=trainLabels.astype(int)\n",
    "    testLabels=testLabels.astype(int)#二值化\n",
    "    \n",
    "    rfc = RandomForestClassifier(class_weight='balanced',random_state=42)                      #不调参\n",
    "    rfc = rfc.fit(trainData, trainLabels)                 #用训练集数据训练模型\n",
    "    pred = rfc.predict(testData)\n",
    "    result = rfc.score(testData, testLabels)\n",
    "    proba = rfc.predict_proba(testData)[:,1]\n",
    "    rocauc = roc_auc_score(testLabels, proba)\n",
    "    recall = recall_score(testLabels, pred)\n",
    "    precision = precision_score(testLabels, pred)\n",
    "    print(resultAnalysis(testData,testLabels,pred,proba,_module='A'))\n",
    "    print(\"\\tAccuracy:{:.3f}\".format(result))\n",
    "    print(\"\\tPrecision:{:.3f}\".format(precision))\n",
    "    print(\"\\tRecall:{:.3f}\".format(recall_score(testLabels,pred)))\n",
    "    print(\"\\tAUC:{:.3f}\".format(roc_auc_score(testLabels,proba)))\n",
    "    return pred\n",
    "RFC(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getROCFig(testLabels,score):\n",
    "    fpr,tpr,thresholds = roc_curve(testLabels,score)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.3f)' % rocauc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-k-100-PCA-RFC.dat written completed.\n"
     ]
    }
   ],
   "source": [
    "#r2,rfc_preds=RFC(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels)\n",
    "getPredictionFile('output-k-100-PCA-RFC.dat', rfc_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大得分：0.8915844875189535 子树数量为：121\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 调参，绘制学习曲线来调参n_estimators（对随机森林影响最大）\n",
    "score_lt = []\n",
    "\n",
    "# 每隔10步建立一个随机森林，获得不同n_estimators的得分\n",
    "for i in range(50,200,10):\n",
    "    rfc = RandomForestClassifier(n_estimators=i+1,random_state=42)\n",
    "    score = cross_val_score(rfc, PCA_Data, all_labels.astype(int), cv=10,scoring='roc_auc').mean()\n",
    "    score_lt.append(score)\n",
    "score_max = max(score_lt)\n",
    "print('最大得分：{}'.format(score_max),\n",
    "      '子树数量为：{}'.format(score_lt.index(score_max)*10+1))\n",
    "\n",
    "# 绘制学习曲线\n",
    "x = np.arange(51,201,10)\n",
    "plt.subplot(111)\n",
    "plt.plot(x, score_lt, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn.metrics.roc_auc_score()的使用方法\n",
    "\n",
    ">sklearn.metrics.roc_auc_score(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)\n",
    "\n",
    "* 参数说明\n",
    "\n",
    "y_true：真实的标签。形状(n_samples，)或(n_samples, n_classes)。二分类的形状(n_samples，1)，而多标签情况的形状(n_samples, n_classes)。\n",
    "\n",
    "y_score：目标分数。形状(n_samples，)或(n_samples, n_classes)。二分类情况形状(n_samples，1)，“分数必须是具有较大标签的类的分数”，通俗点理解:模型打分的第二列。举个例子:模型输入的得分是一个数组[0.98361117 0.01638886]，索引是其类别，这里“较大标签类的分数”，指的是索引为1的分数：0.01638886，也就是正例的预测得分。\n",
    "\n",
    "average='macro'：二分类时，该参数可以忽略。用于多分类，' micro '：将标签指标矩阵的每个元素看作一个标签，计算全局的指标。' macro '：计算每个标签的指标，并找到它们的未加权平均值。这并没有考虑标签的不平衡。' weighted '：计算每个标签的指标，并找到它们的平均值，根据支持度(每个标签的真实实例的数量)进行加权。(多分类的问题在下一篇文章中解释)\n",
    "\n",
    "sample_weight=None：样本权重。形状(n_samples，)，默认=无。\n",
    "\n",
    "max_fpr=None：\n",
    "\n",
    "multi_class='raise'：(多分类的问题在下一篇文章中解释)\n",
    "\n",
    "labels=None：\n",
    "\n",
    "* 输出：\n",
    "\n",
    "auc：是一个float的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_Data = np.vstack((PCA_projected_trainData,PCA_projected_testData))\n",
    "all_labels = np.hstack((train_labels,test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train model RF: 0.239880800 seconds\n",
      "Accuracy     0.931\n",
      "Precision    0.632\n",
      "Recall       0.706\n",
      "F1_score     0.667\n",
      "AUC           0.89\n",
      "AUPRC        0.474\n",
      "Name: non-avg, dtype: object\n",
      "[[302  14]\n",
      " [ 10  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       316\n",
      "           1       0.63      0.71      0.67        34\n",
      "\n",
      "    accuracy                           0.93       350\n",
      "   macro avg       0.80      0.83      0.81       350\n",
      "weighted avg       0.94      0.93      0.93       350\n",
      "\n",
      "\tAccuracy:0.931\n",
      "\tPrecision:0.632\n",
      "\tRecall:0.706\n",
      "\tAUC:0.890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier     #随机森林\n",
    "def RFC2(trainData,trainLabels, testData,testLabels,paramdict):\n",
    "    \n",
    "    trainLabels=trainLabels.astype(int)\n",
    "    testLabels=testLabels.astype(int)#二值化\n",
    "    #paramdict={'n_estimators':63, 'max_depth':5,'criterion':'entropy','class_weight':'balanced','random_state':42}\n",
    "    rfc = RandomForestClassifier(n_estimators=paramdict['n_estimators'], min_samples_split=paramdict['min_samples_split'],\n",
    "                                  min_weight_fraction_leaf=paramdict['min_weight_fraction_leaf'],criterion=paramdict['criterion'],\n",
    "                                 class_weight='balanced',random_state=paramdict['random_state']) \n",
    "    #rfc = RandomForestClassifier(n_estimators=63, max_depth=5,criterion='entropy',class_weight='balanced',random_state=42)\n",
    "    start = time()\n",
    "    rfc = rfc.fit(trainData, trainLabels)                 #用训练集数据训练模型\n",
    "    end = time()\n",
    "    elapsed = end - start\n",
    "    print(\"Time to train model RF: %.9f seconds\" % elapsed)\n",
    "    pred = rfc.predict(testData)\n",
    "    result = rfc.score(testData, testLabels)\n",
    "    proba = rfc.predict_proba(testData)[:,1]\n",
    "    rocauc = roc_auc_score(testLabels, proba)\n",
    "    recall = recall_score(testLabels, pred)\n",
    "    precision = precision_score(testLabels, pred)\n",
    "    print(resultAnalysis(testData,testLabels,pred,proba,))\n",
    "    print(\"\\tAccuracy:{:.3f}\".format(result))\n",
    "    print(\"\\tPrecision:{:.3f}\".format(precision))\n",
    "    print(\"\\tRecall:{:.3f}\".format(recall_score(testLabels,pred)))\n",
    "    print(\"\\tAUC:{:.3f}\".format(roc_auc_score(testLabels,proba)))\n",
    "    return pred\n",
    "#GS.fit(PCA_projected_trainData, train_labels)\n",
    "#print(GS.best_params_)\n",
    "#print(GS.best_score_)\n",
    "\n",
    "parameters={'n_estimators':150, 'max_depth':5,'min_samples_split':9, 'min_weight_fraction_leaf':0.41,\n",
    "            'criterion':'gini','class_weight':'balanced','random_state':42}\n",
    "RFC2(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train XGBoost model: 0.138203382 seconds\n",
      "Accuracy     0.889\n",
      "Precision    0.462\n",
      "Recall       0.882\n",
      "F1_score     0.606\n",
      "AUC          0.908\n",
      "AUPRC        0.419\n",
      "Name: non-avg, dtype: object\n",
      "[[281  35]\n",
      " [  4  30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       316\n",
      "           1       0.46      0.88      0.61        34\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.72      0.89      0.77       350\n",
      "weighted avg       0.94      0.89      0.90       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from time import *\n",
    "\n",
    "#def load_csv(path):\n",
    "#    df = pd.read_csv(path)\n",
    "#    target = df['cls']\n",
    "#    df = df.drop(['cls'], axis=1)\n",
    "#    return xgb.DMatrix(df.values, label=target.values)\n",
    "\n",
    "#dtest = load_csv('/hdd/hdd1/twonormData/t1000.csv')\n",
    "#xgb.DMatrix(PCA_projected_trainData, label=train_labels.astype(int))\n",
    "def evaluate(trainData,trainLabels, testData,testLabels, num_trees=100,max_depth=10,num_jobs=-1):\n",
    "    trainLabels=trainLabels.astype(int)\n",
    "    testLabels=testLabels.astype(int)\n",
    "    dtrain = xgb.DMatrix(trainData, label=trainLabels)\n",
    "    dtest = xgb.DMatrix(testData, label=testLabels)\n",
    "    param = {'num_parallel_tree':num_trees, 'max_depth':max_depth, 'objective':'binary:logistic',\n",
    "        'nthread':num_jobs, 'colsample_bylevel':1/np.sqrt(len(trainLabels)),'scale_pos_weight':10}\n",
    "    start = time()\n",
    "    model = xgb.train(param, dtrain, 1)\n",
    "    # 性能评估以XGboost为例\n",
    "    #xgb = xgb.XGBClassifier()\n",
    "    # 对训练集训练模型\n",
    "    #xgb.fit(trainData,trainLabels)\n",
    "    # 对测试集进行预测\n",
    "    #y_pred = xgb.predict(testData)\n",
    "    end = time()\n",
    "    elapsed = end - start\n",
    "    print(\"Time to train XGBoost model: %.9f seconds\" % elapsed)\n",
    "    prediction = model.predict(dtest)\n",
    "    #proba = model.predict_proba(testData)[:,1]\n",
    "    #print(prediction.shape)\n",
    "    length=len(prediction)\n",
    "    proba = np.stack([[1-a for a in prediction],prediction],axis=-1)\n",
    "    pred=[]\n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i] >0.45:\n",
    "            pred.append(1)\n",
    "        else:pred.append(0)\n",
    "    \n",
    "    #print(pred)\n",
    "    #print(\"Accuracy = %.3f\" % np.mean(prediction == dtest.get_label()))\n",
    "    print(resultAnalysis(testData,testLabels,pred,prediction))\n",
    "\n",
    "evaluate(PCA_projected_trainData,train_labels, PCA_projected_testData,test_labels,)    #choose your own parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参是一个非常重要的步骤，可以帮助我们优化机器学习算法的表现。对于sklearn随机森林算法，调参需要注意以下几点：\n",
    "\n",
    "n_estimators：随机森林中树的数量。增加这个参数可以提高算法的表现，但同时会使得算法的计算时间变长。因此，需要根据具体情况进行调整。\n",
    "\n",
    "max_depth：树的最大深度。增加这个参数可以提高算法的表现，但同时也会使得算法的计算时间变长。需要注意的是，如果max_depth设置太大，会导致过拟合的问题。\n",
    "\n",
    "min_samples_split：节点进行分裂所需的最小样本数量。增加这个参数可以防止过拟合，但会使得算法的表现变差。\n",
    "\n",
    "min_samples_leaf：叶节点所需的最小样本数量。增加这个参数可以防止过拟合，但会使得算法的表现变差。\n",
    "\n",
    "max_features：特征随机选择的个数。增加这个参数可以提高算法的表现，但也会增加算法的计算时间。\n",
    "\n",
    "bootstrap：是否有放回地进行采样。如果设置为False，会使得随机森林变成极端随机森林。\n",
    "\n",
    "criterion：衡量分裂质量的准则。一般选择“gini”或“entropy”。\n",
    "\n",
    "## Grid Search-网格搜索\n",
    "调参的过程可以使用网格搜索(Grid Search)或随机搜索(Random Search)等方法进行。可以通过如下代码进行调参：\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# 设置要调整的参数\n",
    "parameters = {'n_estimators': [10, 50, 100],\n",
    "              'max_depth': [1, 5, 10],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2],\n",
    "              'max_features': [2, 4],\n",
    "              'bootstrap': [True, False],\n",
    "              'criterion': ['gini', 'entropy']}\n",
    "\n",
    "# 使用网格搜索进行调参\n",
    "grid_search = GridSearchCV(clf, parameters, cv=3, n_jobs=1, verbose=1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 输出最佳的参数组合和得分\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "```\n",
    "在网格搜索的过程中，我们首先创建了一个空的随机森林分类器，然后设置了要调整的参数。我们还设置了交叉验证的次数(cv)和并行处理的数量(n_jobs)。然后我们使用GridSearchCV函数进行网格搜索，并使用了verbose参数指定详细程度。最后输出最佳的参数组合和得分。\n",
    "\n",
    "## 贝叶斯优化\n",
    "scikit-learn里的内置贝叶斯优化库为BayesSearchCV，该库可以在超参数空间中使用朴素贝叶斯优化算法，以尝试找到最佳超参数组合。BayesSearchCV需要设定要优化的超参数的搜索范围和目标指标，并为算法提供模型评估器。\n",
    "\n",
    "下面是一个简单的随机森林模型的贝叶斯优化调参示例代码：\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# 定义随机森林模型并设定超参数空间\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "param_dist = {'max_depth': Integer(10, 50),\n",
    "              'min_samples_split': Integer(2, 10),\n",
    "              'min_samples_leaf': Integer(1, 10),\n",
    "              'max_features': Real(0.1, 1.0)}\n",
    "\n",
    "# 使用交叉验证来对模型进行评估\n",
    "def objective_func(params):\n",
    "    rf.set_params(**params)\n",
    "    return -np.mean(cross_val_score(rf, X, y, cv=5, scoring='f1'))\n",
    "\n",
    "# 在超参数空间上运用贝叶斯搜索来优化模型\n",
    "opt = BayesSearchCV(rf,\n",
    "                    param_dist,\n",
    "                    n_iter=25,\n",
    "                    scoring='f1',\n",
    "                    cv=5,\n",
    "                    random_state=0)\n",
    "opt.fit(X, y)\n",
    "```\n",
    "在上面的代码中，使用了sklearn的内置贝叶斯优化库BayesSearchCV。首先定义了一个随机森林模型并设定了超参数空间，然后使用交叉验证评估模型的表现，并将评估结果作为目标函数。最后，在超参数空间上使用BayesSearchCV进行参数搜索，搜索结束后可以使用如下代码来输出参数搜索的结果：\n",
    "\n",
    "```python\n",
    "print(\"Best F1 Score:3f\" opt.best_score_)\n",
    "print(\"Best Parameters:s\" str(opt.best_params_))\n",
    "```\n",
    "使用BayesSearchCV时，可以通过参数n_iter来控制贝叶斯优化的迭代次数，通常n_iter要比随机搜索大，这样可以更好地探索超参数空间。同时，参数cv指定了用于交叉验证的数据集的拆分数量，一般默认为5。scoring参数用于指定评估指标，这里选择了F1得分，因为它同时考虑了准确率和召回率，是一个比较全面的指标。\n",
    "\n",
    "需要注意的是，由于贝叶斯优化是一种基于概率的优化方法，因此它的寻优速度可能会受到几个因素的影响，例如超参数的数量和范围、目标函数的复杂性等。因此，在进行调参时，需要根据实际情况和计算资源情况进行适当的调整和控制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_split': 9}\n",
      "0.9163436078484622\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':np.arange(1,20,1),'min_samples_split':np.arange(2, 2+20, 1)} \n",
    "#param_grid ={'max_features':np.arange(5,30,1),'min_samples_leaf':np.arange(1, 1+10, 1),'min_samples_split':np.arange(2, 2+20, 1),'criterion':['gini', 'entropy']}\n",
    "rfc = RandomForestClassifier(n_estimators=120,oob_score=True,class_weight='balanced',criterion='gini',random_state=42) \n",
    "GS = GridSearchCV(rfc,param_grid,cv=10,scoring='roc_auc') \n",
    "GS.fit(PCA_Data,all_labels.astype(int))\n",
    "print(GS.best_params_)\n",
    "print(GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
