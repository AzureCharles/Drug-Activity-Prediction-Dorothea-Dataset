{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9240342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2, 1, 0,\n",
      "        2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1,\n",
      "        0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0,\n",
      "        0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([120])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载数据\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 转换为Tensor\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "\n",
    "y_train = torch.tensor(y_train).long()\n",
    "y_test = torch.tensor(y_test).long()\n",
    "\n",
    "#y_train = one_hot(torch.tensor(y_train, dtype=int))\n",
    "#y_test = one_hot(torch.tensor(y_test, dtype=int))\n",
    "print(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4fd773d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集类\n",
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]\n",
    "    \n",
    "# 定义模型\n",
    "class RBF(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(RBF, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.exp(-torch.norm(x - self.linear.weight, dim=1) ** 2).unsqueeze(1)\n",
    "\n",
    "class MultiKernelNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MultiKernelNet, self).__init__()\n",
    "        #self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.rbf = RBF(input_dim, hidden_dim) # RBF kernel\n",
    "        self.linear = nn.Linear(hidden_dim, hidden_dim) # linear kernel\n",
    "        self.rbf2 = RBF(hidden_dim, hidden_dim) # RBF kernel\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # convert to (batch_size, class_num)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 第一层：使用RBF核函数\n",
    "        rbf_output = torch.matmul(self.rbf(x),self.rbf(x).t())\n",
    "        #print('RBF输出结果{},尺寸为: {}'.format(rbf_output,rbf_output.shape))\n",
    "        #rbf_output = torch.relu(rbf_output)\n",
    "        # 第二层：使用线性核函数\n",
    "        linear_output = self.layer2(torch.matmul(self.linear(rbf_output),self.linear(rbf_output).t()))\n",
    "        #rbf2_output = self.layer2(torch.matmul(self.rbf2(rbf_output),self.rbf2(rbf_output).t()))\n",
    "        # 求取最终输出\n",
    "        output = F.softmax(linear_output, dim=1)\n",
    "        #output = F.softmax(rbf2_output, dim=1)\n",
    "        #print('输出结果{},尺寸为: {}'.format(output,output.shape))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, average_precision_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def resultAnalysis(testData,testLabels,pred,proba,_module=None):\n",
    "    xmodulelist = ['macro','micro','weighted','non-avg']\n",
    "    criteion = ['Accuracy','Precision','Recall','F1_score','AUC','AUPRC']\n",
    "    df = pd.DataFrame(index=xmodulelist,columns=criteion)\n",
    "    \n",
    "    \n",
    "    if _module not in xmodulelist:\n",
    "        \n",
    "        df['Accuracy']['non-avg']=round(accuracy_score(testLabels,pred),3)\n",
    "        df['Precision']['non-avg']=round(precision_score(testLabels,pred,),3)\n",
    "        df['Recall']['non-avg']=round(recall_score(testLabels,pred,),3)\n",
    "        df['AUC']['non-avg']=round(roc_auc_score(testLabels,proba,),3)\n",
    "        df['AUPRC']['non-avg']=round(average_precision_score(testLabels,pred,),3)\n",
    "        df['F1_score']['non-avg']=round(f1_score(testLabels,pred,),3)\n",
    "        print(df.iloc[3,:])\n",
    "            \n",
    "    else:\n",
    "        df['Accuracy'][_module]=round(accuracy_score(testLabels,pred),3)\n",
    "        df['Precision'][_module]=round(precision_score(testLabels,pred,average=_module),3)\n",
    "        df['Recall'][_module]=round(recall_score(testLabels,pred,average=_module),3)\n",
    "        df['AUC'][_module]=round(roc_auc_score(testLabels,proba,average=_module),3)\n",
    "        df['AUPRC'][_module]=round(average_precision_score(testLabels,pred,average=_module),3)\n",
    "        df['F1_score'][_module]=round(f1_score(testLabels,pred,average=_module),3)\n",
    "        print(df.loc[_module,:])\n",
    "    print(confusion_matrix(testLabels,pred))\n",
    "    return classification_report(testLabels,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "class SVMC(nn.Module):\n",
    "    def __init__(self, in_features, out_features,k='linear'):\n",
    "        super(SVMC, self).__init__()\n",
    "        #self.svmc = nn.Linear(in_features, out_features)\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        clf_proba = svm.SVC(kernel=k,C=1.0,probability=True).fit(trainData,trainLabels)\n",
    "        clf_pred = clf_proba.predict(testData)\n",
    "        result = clf_proba.score(testData, testLabels)\n",
    "        score = clf_proba.decision_function(testData)\n",
    "\n",
    "        rocauc = roc_auc_score(testLabels, score)\n",
    "        recall = recall_score(testLabels, clf_pred)\n",
    "        precision = precision_score(testLabels, clf_pred)\n",
    "        print(\"The kernel {} prediction is:\".format(k))\n",
    "        print(resultAnalysis(testData,testLabels,clf_pred,score,))\n",
    "        return torch.exp(-torch.norm(x - self.linear.weight, dim=1) ** 2).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d3874631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 10\n",
    "output_dim = 3\n",
    "lr = 0.01\n",
    "batch_size = 10\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e130995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train accuracy: 0.3250, Test accuracy: 0.3667\n",
      "Epoch 2: Train accuracy: 0.3417, Test accuracy: 0.3000\n",
      "Epoch 3: Train accuracy: 0.3417, Test accuracy: 0.3000\n",
      "Epoch 4: Train accuracy: 0.4583, Test accuracy: 0.5333\n",
      "Epoch 5: Train accuracy: 0.3833, Test accuracy: 0.4667\n",
      "Epoch 6: Train accuracy: 0.3833, Test accuracy: 0.4667\n",
      "Epoch 7: Train accuracy: 0.4000, Test accuracy: 0.4667\n",
      "Epoch 8: Train accuracy: 0.5333, Test accuracy: 0.4000\n",
      "Epoch 9: Train accuracy: 0.4667, Test accuracy: 0.4667\n",
      "Epoch 10: Train accuracy: 0.4917, Test accuracy: 0.5000\n",
      "Epoch 11: Train accuracy: 0.5083, Test accuracy: 0.5000\n",
      "Epoch 12: Train accuracy: 0.4667, Test accuracy: 0.4667\n",
      "Epoch 13: Train accuracy: 0.4083, Test accuracy: 0.4667\n",
      "Epoch 14: Train accuracy: 0.4917, Test accuracy: 0.3667\n",
      "Epoch 15: Train accuracy: 0.4583, Test accuracy: 0.4000\n",
      "Epoch 16: Train accuracy: 0.4750, Test accuracy: 0.3667\n",
      "Epoch 17: Train accuracy: 0.5167, Test accuracy: 0.3667\n",
      "Epoch 18: Train accuracy: 0.4917, Test accuracy: 0.3667\n",
      "Epoch 19: Train accuracy: 0.5167, Test accuracy: 0.3667\n",
      "Epoch 20: Train accuracy: 0.4750, Test accuracy: 0.4000\n",
      "Epoch 21: Train accuracy: 0.5833, Test accuracy: 0.5333\n",
      "Epoch 22: Train accuracy: 0.4917, Test accuracy: 0.5333\n",
      "Epoch 23: Train accuracy: 0.5417, Test accuracy: 0.5000\n",
      "Epoch 24: Train accuracy: 0.4917, Test accuracy: 0.5333\n",
      "Epoch 25: Train accuracy: 0.5583, Test accuracy: 0.5333\n",
      "Epoch 26: Train accuracy: 0.4833, Test accuracy: 0.5000\n",
      "Epoch 27: Train accuracy: 0.5500, Test accuracy: 0.5333\n",
      "Epoch 28: Train accuracy: 0.5500, Test accuracy: 0.5333\n",
      "Epoch 29: Train accuracy: 0.5417, Test accuracy: 0.5333\n",
      "Epoch 30: Train accuracy: 0.4833, Test accuracy: 0.5333\n",
      "Epoch 31: Train accuracy: 0.4750, Test accuracy: 0.5000\n",
      "Epoch 32: Train accuracy: 0.5083, Test accuracy: 0.5333\n",
      "Epoch 33: Train accuracy: 0.5083, Test accuracy: 0.5667\n",
      "Epoch 34: Train accuracy: 0.5083, Test accuracy: 0.5667\n",
      "Epoch 35: Train accuracy: 0.5583, Test accuracy: 0.5667\n",
      "Epoch 36: Train accuracy: 0.5250, Test accuracy: 0.5667\n",
      "Epoch 37: Train accuracy: 0.5500, Test accuracy: 0.5667\n",
      "Epoch 38: Train accuracy: 0.5833, Test accuracy: 0.5667\n",
      "Epoch 39: Train accuracy: 0.5250, Test accuracy: 0.5667\n",
      "Epoch 40: Train accuracy: 0.5833, Test accuracy: 0.5667\n",
      "Epoch 41: Train accuracy: 0.4833, Test accuracy: 0.5667\n",
      "Epoch 42: Train accuracy: 0.6000, Test accuracy: 0.5667\n",
      "Epoch 43: Train accuracy: 0.5250, Test accuracy: 0.6000\n",
      "Epoch 44: Train accuracy: 0.5583, Test accuracy: 0.6000\n",
      "Epoch 45: Train accuracy: 0.5417, Test accuracy: 0.6000\n",
      "Epoch 46: Train accuracy: 0.5417, Test accuracy: 0.6000\n",
      "Epoch 47: Train accuracy: 0.6083, Test accuracy: 0.6000\n",
      "Epoch 48: Train accuracy: 0.5750, Test accuracy: 0.6000\n",
      "Epoch 49: Train accuracy: 0.5167, Test accuracy: 0.6000\n",
      "Epoch 50: Train accuracy: 0.5583, Test accuracy: 0.6000\n",
      "Epoch 51: Train accuracy: 0.5833, Test accuracy: 0.6000\n",
      "Epoch 52: Train accuracy: 0.5167, Test accuracy: 0.6000\n",
      "Epoch 53: Train accuracy: 0.5417, Test accuracy: 0.6000\n",
      "Epoch 54: Train accuracy: 0.6083, Test accuracy: 0.6000\n",
      "Epoch 55: Train accuracy: 0.5333, Test accuracy: 0.6000\n",
      "Epoch 56: Train accuracy: 0.6083, Test accuracy: 0.6000\n",
      "Epoch 57: Train accuracy: 0.5250, Test accuracy: 0.6000\n",
      "Epoch 58: Train accuracy: 0.5333, Test accuracy: 0.6000\n",
      "Epoch 59: Train accuracy: 0.5250, Test accuracy: 0.5333\n",
      "Epoch 60: Train accuracy: 0.5667, Test accuracy: 0.5333\n",
      "Epoch 61: Train accuracy: 0.5083, Test accuracy: 0.5667\n",
      "Epoch 62: Train accuracy: 0.5583, Test accuracy: 0.6000\n",
      "Epoch 63: Train accuracy: 0.5583, Test accuracy: 0.5667\n",
      "Epoch 64: Train accuracy: 0.5500, Test accuracy: 0.6000\n",
      "Epoch 65: Train accuracy: 0.5667, Test accuracy: 0.5333\n",
      "Epoch 66: Train accuracy: 0.5333, Test accuracy: 0.5333\n",
      "Epoch 67: Train accuracy: 0.5583, Test accuracy: 0.5333\n",
      "Epoch 68: Train accuracy: 0.5500, Test accuracy: 0.5333\n",
      "Epoch 69: Train accuracy: 0.5583, Test accuracy: 0.5333\n",
      "Epoch 70: Train accuracy: 0.5333, Test accuracy: 0.5000\n",
      "Epoch 71: Train accuracy: 0.5833, Test accuracy: 0.5333\n",
      "Epoch 72: Train accuracy: 0.5500, Test accuracy: 0.5333\n",
      "Epoch 73: Train accuracy: 0.5917, Test accuracy: 0.5333\n",
      "Epoch 74: Train accuracy: 0.5667, Test accuracy: 0.5333\n",
      "Epoch 75: Train accuracy: 0.5667, Test accuracy: 0.5000\n",
      "Epoch 76: Train accuracy: 0.5500, Test accuracy: 0.5000\n",
      "Epoch 77: Train accuracy: 0.5083, Test accuracy: 0.5333\n",
      "Epoch 78: Train accuracy: 0.5833, Test accuracy: 0.5333\n",
      "Epoch 79: Train accuracy: 0.5750, Test accuracy: 0.5000\n",
      "Epoch 80: Train accuracy: 0.5917, Test accuracy: 0.5000\n",
      "Epoch 81: Train accuracy: 0.5417, Test accuracy: 0.6000\n",
      "Epoch 82: Train accuracy: 0.6083, Test accuracy: 0.5667\n",
      "Epoch 83: Train accuracy: 0.5917, Test accuracy: 0.5667\n",
      "Epoch 84: Train accuracy: 0.5833, Test accuracy: 0.5667\n",
      "Epoch 85: Train accuracy: 0.5417, Test accuracy: 0.5667\n",
      "Epoch 86: Train accuracy: 0.5583, Test accuracy: 0.5667\n",
      "Epoch 87: Train accuracy: 0.5917, Test accuracy: 0.5667\n",
      "Epoch 88: Train accuracy: 0.5583, Test accuracy: 0.5667\n",
      "Epoch 89: Train accuracy: 0.5583, Test accuracy: 0.5667\n",
      "Epoch 90: Train accuracy: 0.5833, Test accuracy: 0.6000\n",
      "Epoch 91: Train accuracy: 0.6083, Test accuracy: 0.6000\n",
      "Epoch 92: Train accuracy: 0.5833, Test accuracy: 0.5667\n",
      "Epoch 93: Train accuracy: 0.5667, Test accuracy: 0.5667\n",
      "Epoch 94: Train accuracy: 0.5833, Test accuracy: 0.5667\n",
      "Epoch 95: Train accuracy: 0.5833, Test accuracy: 0.5667\n",
      "Epoch 96: Train accuracy: 0.5750, Test accuracy: 0.5667\n",
      "Epoch 97: Train accuracy: 0.6083, Test accuracy: 0.5667\n",
      "Epoch 98: Train accuracy: 0.5917, Test accuracy: 0.5667\n",
      "Epoch 99: Train accuracy: 0.5833, Test accuracy: 0.5667\n",
      "Epoch 100: Train accuracy: 0.5750, Test accuracy: 0.5667\n"
     ]
    }
   ],
   "source": [
    "# 定义模型、损失函数和优化器\n",
    "model = MultiKernelNet(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = IrisDataset(X_train, y_train)\n",
    "test_dataset = IrisDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 定义训练和测试函数\n",
    "def train(model, criterion, optimizer, train_loader):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        #print('输出结果{},尺寸为: {}'.format(output,output.shape))\n",
    "        #print('目标对象{},尺寸为: {}'.format(target,target.shape))\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(model, criterion, optimizer, train_loader)\n",
    "    train_acc = test(model, train_loader)\n",
    "    test_acc = test(model, test_loader)\n",
    "    print(f\"Epoch {epoch+1}: Train accuracy: {train_acc:.4f}, Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee28fa",
   "metadata": {},
   "source": [
    "`torch.nn.Linear`是PyTorch中的一个类，用于定义一个线性变换（linear transformation）。\n",
    "\n",
    "其定义如下：\n",
    "\n",
    "`class torch.nn.Linear(in_features: int, out_features: int, bias: bool = True)`\n",
    "其中，in_features是输入特征的数量，out_features是输出特征的数量，bias表示是否包含偏置（bias）项。\n",
    "\n",
    "`torch.nn.Linear`中包含两个重要的参数：weight和bias。weight是一个大小为(out_features, in_features)的张量，bias是一个大小为(out_features,)的张量。在前向传播的过程中，输入张量会与weight相乘，并加上bias，得到输出张量。\n",
    "\n",
    "以下是`torch.nn.Linear`的一些性质和用法：\n",
    "\n",
    "weight和bias可以通过调用model.parameters()方法获取。\n",
    "\n",
    "在模型训练过程中，PyTorch会自动优化weight和bias，使得模型在训练集上的性能最优。\n",
    "\n",
    "torch.nn.Linear常常用于构建神经网络中的全连接层。例如，可以将多个torch.nn.Linear组合成一个多层感知机（Multilayer Perceptron，MLP）模型。\n",
    "\n",
    "torch.nn.Linear可以通过指定in_features和out_features来定义输入和输出的特征数。这对于不同的任务和数据集可以有不同的取值。\n",
    "\n",
    "torch.nn.Linear还可以设置bias=False，这样就不会在线性变换中加上偏置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e00437d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_53240\\2672181378.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# 前向传播，得到预测结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;31m# 计算损失值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_53240\\2672181378.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# 计算第一层的输出，使用RBF核函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moutput1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#self.linear1.weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;31m# 计算第二层的输出，使用线性核函数和偏置\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0moutput2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;31m#self.linear2.weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_53240\\2672181378.py\u001b[0m in \u001b[0;36mrbf_kernel\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# 计算两个张量之间的欧氏距离的平方\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m# 计算RBF核函数的值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# 导入相关库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 定义RBF核函数\n",
    "def rbf_kernel(x):\n",
    "    # 计算两个张量之间的欧氏距离的平方\n",
    "    dist = torch.exp(-torch.norm(x - self.linear.weight, dim=1) ** 2)\n",
    "    # 计算RBF核函数的值\n",
    "    return torch.sum(dist * dist,dim=1)\n",
    "\n",
    "# 定义线性核函数\n",
    "def linear_kernel(x):\n",
    "    # 计算两个张量之间的点积\n",
    "    return torch.sum(x * x,dim=1)\n",
    "\n",
    "# 定义二层多核学习模型\n",
    "class MultiKernelModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_size):\n",
    "        super(MultiKernelModel, self).__init__()\n",
    "        # 第一层使用RBF核函数，参数为隐层神经元的权重\n",
    "        self.linear1 = nn.Linear(in_features, hidden_size)\n",
    "        # 第二层使用线性核函数，参数为输出层神经元的权重和偏置\n",
    "        self.linear2 = nn.Linear(hidden_size, out_features)\n",
    "        # 使用softmax函数作为激活函数，得到分类概率\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算第一层的输出，使用RBF核函数\n",
    "        output1 = rbf_kernel(x) #self.linear1.weight\n",
    "        # 计算第二层的输出，使用线性核函数和偏置\n",
    "        output2 = linear_kernel(output1) + self.linear2.bias #self.linear2.weight\n",
    "        # 使用softmax函数得到分类概率\n",
    "        output = self.softmax(output2)\n",
    "        return output\n",
    "\n",
    "# 加载iris数据集，并划分为训练集和测试集\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量，并设置为float类型和long类型\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "# 创建模型实例，设置输入特征数为4，输出类别数为3，隐层神经元数为10\n",
    "model = MultiKernelModel(4, 3, 10)\n",
    "\n",
    "# 定义交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义SGD优化器，设置学习率为0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 设置训练轮数为100\n",
    "epochs = 100\n",
    "\n",
    "# 开始训练过程\n",
    "for epoch in range(epochs):\n",
    "    # 清零梯度\n",
    "    optimizer.zero_grad()\n",
    "    # 前向传播，得到预测结果\n",
    "    output = model(X_train)\n",
    "    # 计算损失值\n",
    "    loss = criterion(output, y_train)\n",
    "    # 反向传播，计算梯度\n",
    "    loss.backward()\n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "    # 打印每轮的损失值和准确率\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    acc = accuracy_score(y_train.numpy(), pred.numpy())\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd683c",
   "metadata": {},
   "source": [
    "一般我们用的R里面的e1071包的svm函数和python的scikit-learn包里的svm函数都是基于libsvm实现的：http://www.csie.ntu.edu.tw/~cjlin/libsvm/libsvm\n",
    "libsvm提供了下列几个核函数：\n",
    "\n",
    "linear:u'\\*v\n",
    "\n",
    "polynomial:(gamma*u'*v + coef0)^degree\n",
    "    \n",
    "radial basis:exp(-gamma*|u-v|^2)\n",
    "        \n",
    "sigmoid:tanh(gamma*u'*v + coef0)\n",
    "             \n",
    "通常来说，个人经验RBF kernel是第一选择，几乎效果都是最好的。此外，linear kernel也有用武之地，（其实linear kernel本身就是RBF的一种特殊情况），因为当features的数量很多的时候，linear kernel的速度优势比较明显。当然有时间当然最好是都试一遍，看看哪个更符合自己的数据分布特性了。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b7fed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 将测试数据移动到GPU上\n",
    "    X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "    # 前向传播\n",
    "    outputs = model(X_test)\n",
    "\n",
    "    # 预测类别\n",
    "    _,predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # 计算预测准确率\n",
    "    total = y_test.size(0)\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "    print('Test Accuracy of the model on the {} test images: {:.2f} %'.format(total, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08859d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 4])\n",
      "tensor([[-1.5065e+00,  1.2492e+00, -1.5676e+00, -1.3154e+00],\n",
      "        [-1.7367e-01,  3.0908e+00, -1.2834e+00, -1.0522e+00],\n",
      "        [ 1.0380e+00,  9.8217e-02,  3.6490e-01,  2.6414e-01],\n",
      "        [-1.2642e+00,  7.8881e-01, -1.2266e+00, -1.3154e+00],\n",
      "        [-1.7489e+00,  3.2841e-01, -1.3971e+00, -1.3154e+00],\n",
      "        [ 5.5333e-01, -1.2830e+00,  7.0592e-01,  9.2230e-01],\n",
      "        [ 6.7450e-01,  3.2841e-01,  4.2173e-01,  3.9577e-01],\n",
      "        [-7.7951e-01,  1.0190e+00, -1.2834e+00, -1.3154e+00],\n",
      "        [-1.0218e+00,  1.2492e+00, -1.3402e+00, -1.3154e+00],\n",
      "        [-7.7951e-01,  2.4002e+00, -1.2834e+00, -1.4471e+00],\n",
      "        [-5.2506e-02, -8.2257e-01,  7.6276e-01,  9.2230e-01],\n",
      "        [ 1.8983e-01,  7.8881e-01,  4.2173e-01,  5.2741e-01],\n",
      "        [ 1.0380e+00,  9.8217e-02,  5.3541e-01,  3.9577e-01],\n",
      "        [-5.3718e-01,  1.9398e+00, -1.3971e+00, -1.0522e+00],\n",
      "        [-5.3718e-01,  1.4794e+00, -1.2834e+00, -1.3154e+00],\n",
      "        [-4.1601e-01, -1.5132e+00, -3.2966e-02, -2.6239e-01],\n",
      "        [ 5.5333e-01, -5.9237e-01,  7.6276e-01,  3.9577e-01],\n",
      "        [ 6.7450e-01,  9.8217e-02,  9.9011e-01,  7.9067e-01],\n",
      "        [ 9.1684e-01, -1.3198e-01,  3.6490e-01,  2.6414e-01],\n",
      "        [ 1.6438e+00,  1.2492e+00,  1.3311e+00,  1.7121e+00],\n",
      "        [-1.7367e-01, -3.6218e-01,  2.5122e-01,  1.3251e-01],\n",
      "        [ 2.1285e+00, -1.3198e-01,  1.6153e+00,  1.1856e+00],\n",
      "        [-2.9484e-01, -1.3198e-01,  4.2173e-01,  3.9577e-01],\n",
      "        [-9.0068e-01,  1.0190e+00, -1.3402e+00, -1.3154e+00],\n",
      "        [ 2.2497e+00, -5.9237e-01,  1.6722e+00,  1.0539e+00],\n",
      "        [-5.2506e-02, -8.2257e-01,  1.9438e-01, -2.6239e-01],\n",
      "        [-7.7951e-01,  7.8881e-01, -1.3402e+00, -1.3154e+00],\n",
      "        [-1.0218e+00,  1.0190e+00, -1.3971e+00, -1.1838e+00],\n",
      "        [-9.0068e-01,  1.7096e+00, -1.0560e+00, -1.0522e+00],\n",
      "        [-1.0218e+00, -2.4339e+00, -1.4664e-01, -2.6239e-01],\n",
      "        [ 5.5333e-01, -8.2257e-01,  6.4908e-01,  7.9067e-01],\n",
      "        [-1.2642e+00,  7.8881e-01, -1.0560e+00, -1.3154e+00],\n",
      "        [-1.0218e+00, -1.3198e-01, -1.2266e+00, -1.3154e+00],\n",
      "        [-9.0068e-01,  5.5861e-01, -1.1697e+00, -9.2055e-01],\n",
      "        [-2.9484e-01, -8.2257e-01,  2.5122e-01,  1.3251e-01],\n",
      "        [-9.0068e-01,  7.8881e-01, -1.2834e+00, -1.3154e+00],\n",
      "        [-1.7367e-01, -1.3198e-01,  2.5122e-01,  8.7755e-04],\n",
      "        [ 2.2497e+00,  1.7096e+00,  1.6722e+00,  1.3172e+00],\n",
      "        [-1.5065e+00,  3.2841e-01, -1.3402e+00, -1.3154e+00],\n",
      "        [ 4.3217e-01, -3.6218e-01,  3.0806e-01,  1.3251e-01],\n",
      "        [-1.7367e-01, -1.2830e+00,  7.0592e-01,  1.0539e+00],\n",
      "        [-4.1601e-01,  2.6304e+00, -1.3402e+00, -1.3154e+00],\n",
      "        [ 1.8983e-01, -1.3198e-01,  5.9225e-01,  7.9067e-01],\n",
      "        [-5.2506e-02, -8.2257e-01,  7.6276e-01,  9.2230e-01],\n",
      "        [ 1.8983e-01, -1.9736e+00,  1.3755e-01, -2.6239e-01],\n",
      "        [-5.3718e-01, -1.3198e-01,  4.2173e-01,  3.9577e-01],\n",
      "        [ 4.3217e-01,  7.8881e-01,  9.3327e-01,  1.4488e+00],\n",
      "        [-4.1601e-01, -1.7434e+00,  1.3755e-01,  1.3251e-01],\n",
      "        [-5.3718e-01,  1.9398e+00, -1.1697e+00, -1.0522e+00],\n",
      "        [-1.0218e+00, -1.7434e+00, -2.6032e-01, -2.6239e-01],\n",
      "        [ 6.7450e-01, -8.2257e-01,  8.7643e-01,  9.2230e-01],\n",
      "        [-1.0218e+00,  5.5861e-01, -1.3402e+00, -1.3154e+00],\n",
      "        [-1.0218e+00,  3.2841e-01, -1.4539e+00, -1.3154e+00],\n",
      "        [-4.1601e-01, -1.5132e+00,  2.3872e-02, -1.3075e-01],\n",
      "        [ 1.0380e+00, -1.3198e-01,  7.0592e-01,  6.5904e-01],\n",
      "        [-1.1430e+00,  9.8217e-02, -1.2834e+00, -1.3154e+00],\n",
      "        [-5.2506e-02, -5.9237e-01,  7.6276e-01,  1.5805e+00],\n",
      "        [-1.0218e+00,  7.8881e-01, -1.2834e+00, -1.3154e+00],\n",
      "        [-1.0218e+00,  1.0190e+00, -1.2266e+00, -7.8892e-01],\n",
      "        [ 6.8662e-02,  3.2841e-01,  5.9225e-01,  7.9067e-01],\n",
      "        [-9.0068e-01, -1.2830e+00, -4.3083e-01, -1.3075e-01],\n",
      "        [ 1.2803e+00,  3.2841e-01,  1.1038e+00,  1.4488e+00],\n",
      "        [ 1.8983e-01, -8.2257e-01,  7.6276e-01,  5.2741e-01],\n",
      "        [ 3.1100e-01, -1.0528e+00,  1.0469e+00,  2.6414e-01],\n",
      "        [ 2.2497e+00, -1.3198e-01,  1.3311e+00,  1.4488e+00],\n",
      "        [-4.1601e-01, -1.2830e+00,  1.3755e-01,  1.3251e-01],\n",
      "        [-1.7489e+00, -3.6218e-01, -1.3402e+00, -1.3154e+00],\n",
      "        [-1.8700e+00, -1.3198e-01, -1.5107e+00, -1.4471e+00],\n",
      "        [ 1.8983e-01, -1.9736e+00,  7.0592e-01,  3.9577e-01],\n",
      "        [ 1.6438e+00,  3.2841e-01,  1.2743e+00,  7.9067e-01],\n",
      "        [-1.5065e+00,  9.8217e-02, -1.2834e+00, -1.3154e+00],\n",
      "        [-9.0068e-01,  1.0190e+00, -1.3402e+00, -1.1838e+00],\n",
      "        [-1.7489e+00, -1.3198e-01, -1.3971e+00, -1.3154e+00],\n",
      "        [ 5.5333e-01, -1.2830e+00,  6.4908e-01,  3.9577e-01],\n",
      "        [ 5.5333e-01,  7.8881e-01,  1.0469e+00,  1.5805e+00],\n",
      "        [-1.5065e+00,  7.8881e-01, -1.3402e+00, -1.1838e+00],\n",
      "        [ 1.1592e+00, -1.3198e-01,  9.9011e-01,  1.1856e+00],\n",
      "        [ 5.5333e-01,  5.5861e-01,  1.2743e+00,  1.7121e+00],\n",
      "        [-1.3854e+00,  3.2841e-01, -1.3971e+00, -1.3154e+00],\n",
      "        [ 3.1100e-01, -3.6218e-01,  5.3541e-01,  2.6414e-01],\n",
      "        [ 7.9567e-01, -5.9237e-01,  4.7857e-01,  3.9577e-01],\n",
      "        [ 4.3217e-01, -5.9237e-01,  5.9225e-01,  7.9067e-01],\n",
      "        [ 1.4015e+00,  3.2841e-01,  5.3541e-01,  2.6414e-01],\n",
      "        [ 6.7450e-01,  3.2841e-01,  8.7643e-01,  1.4488e+00],\n",
      "        [-9.0068e-01,  1.7096e+00, -1.2266e+00, -1.3154e+00],\n",
      "        [ 1.2803e+00,  9.8217e-02,  9.3327e-01,  1.1856e+00],\n",
      "        [ 6.8662e-02, -1.3198e-01,  2.5122e-01,  3.9577e-01],\n",
      "        [ 7.9567e-01, -1.3198e-01,  8.1960e-01,  1.0539e+00],\n",
      "        [-1.7367e-01, -1.0528e+00, -1.4664e-01, -2.6239e-01],\n",
      "        [-7.7951e-01, -8.2257e-01,  8.0709e-02,  2.6414e-01],\n",
      "        [ 3.1100e-01, -1.3198e-01,  4.7857e-01,  2.6414e-01],\n",
      "        [-1.6277e+00, -1.7434e+00, -1.3971e+00, -1.1838e+00],\n",
      "        [ 9.1684e-01, -3.6218e-01,  4.7857e-01,  1.3251e-01],\n",
      "        [-4.1601e-01, -1.0528e+00,  3.6490e-01,  8.7755e-04],\n",
      "        [-6.5835e-01,  1.4794e+00, -1.2834e+00, -1.3154e+00],\n",
      "        [-2.9484e-01, -1.3198e-01,  1.9438e-01,  1.3251e-01],\n",
      "        [ 1.7650e+00, -3.6218e-01,  1.4448e+00,  7.9067e-01],\n",
      "        [ 1.0380e+00,  5.5861e-01,  1.1038e+00,  1.1856e+00],\n",
      "        [-9.0068e-01,  1.4794e+00, -1.2834e+00, -1.0522e+00],\n",
      "        [-1.1430e+00, -1.5132e+00, -2.6032e-01, -2.6239e-01],\n",
      "        [ 1.0380e+00,  5.5861e-01,  1.1038e+00,  1.7121e+00],\n",
      "        [ 1.6438e+00, -1.3198e-01,  1.1606e+00,  5.2741e-01],\n",
      "        [-1.1430e+00,  1.2492e+00, -1.3402e+00, -1.4471e+00],\n",
      "        [ 1.0380e+00,  9.8217e-02,  1.0469e+00,  1.5805e+00],\n",
      "        [-1.1430e+00, -1.3198e-01, -1.3402e+00, -1.3154e+00],\n",
      "        [ 1.2803e+00,  9.8217e-02,  6.4908e-01,  3.9577e-01],\n",
      "        [ 1.8862e+00, -5.9237e-01,  1.3311e+00,  9.2230e-01],\n",
      "        [ 5.5333e-01, -3.6218e-01,  1.0469e+00,  7.9067e-01],\n",
      "        [-1.7367e-01, -5.9237e-01,  1.9438e-01,  1.3251e-01],\n",
      "        [ 7.9567e-01, -1.3198e-01,  9.9011e-01,  7.9067e-01],\n",
      "        [ 5.5333e-01, -1.7434e+00,  3.6490e-01,  1.3251e-01],\n",
      "        [ 6.7450e-01, -3.6218e-01,  3.0806e-01,  1.3251e-01],\n",
      "        [-2.9484e-01, -5.9237e-01,  6.4908e-01,  1.0539e+00],\n",
      "        [ 6.8662e-02, -1.3198e-01,  7.6276e-01,  7.9067e-01],\n",
      "        [-5.3718e-01,  7.8881e-01, -1.1697e+00, -1.3154e+00],\n",
      "        [ 3.1100e-01, -5.9237e-01,  1.3755e-01,  1.3251e-01],\n",
      "        [-1.1430e+00, -1.2830e+00,  4.2173e-01,  6.5904e-01],\n",
      "        [-5.2506e-02,  2.1700e+00, -1.4539e+00, -1.3154e+00],\n",
      "        [-5.2506e-02, -1.0528e+00,  1.3755e-01,  8.7755e-04],\n",
      "        [ 1.5227e+00, -1.3198e-01,  1.2175e+00,  1.1856e+00]])\n",
      "torch.Size([120])\n",
      "tensor([0., 0., 1., 0., 0., 2., 1., 0., 0., 0., 2., 1., 1., 0., 0., 1., 2., 2.,\n",
      "        1., 2., 1., 2., 1., 0., 2., 1., 0., 0., 0., 1., 2., 0., 0., 0., 1., 0.,\n",
      "        1., 2., 0., 1., 2., 0., 2., 2., 1., 1., 2., 1., 0., 1., 2., 0., 0., 1.,\n",
      "        1., 0., 2., 0., 0., 1., 1., 2., 1., 2., 2., 1., 0., 0., 2., 2., 0., 0.,\n",
      "        0., 1., 2., 0., 2., 2., 0., 1., 1., 2., 1., 2., 0., 2., 1., 2., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 2., 2., 0., 1., 2., 2., 0., 2., 0., 1., 2., 2.,\n",
      "        1., 2., 1., 1., 2., 2., 0., 1., 2., 0., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.size())\n",
    "print(X_train)\n",
    "print(y_train.size())\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b52c52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 2,  4,  6,  8, 10],\n",
       "        [ 3,  6,  9, 12, 15],\n",
       "        [ 4,  8, 12, 16, 20],\n",
       "        [ 5, 10, 15, 20, 25]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# 方法1：使用t()方法\n",
    "a_t = a.t()\n",
    "\n",
    "# 方法2：使用transpose()方法\n",
    "a_t2 = a.transpose(0, 0)\n",
    "\n",
    "#a = torch.tensor([1, 2, 3, 4, 5])\n",
    "a2 = a.unsqueeze(0)  # 在第0个维度上增加一个维度\n",
    "\n",
    "torch.matmul(a2.t(),a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a50d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
